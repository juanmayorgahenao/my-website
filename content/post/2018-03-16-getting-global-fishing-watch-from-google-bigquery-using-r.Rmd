---
title: Getting Global Fishing Watch Data from Google BigQuery using R
author: Juan S. Mayorga
date: '2018-03-16'
slug: getting-global-fishing-watch-from-google-bigquery-using-r
categories: []
tags: []
draft: true
---

```{r set-options, echo=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, fig.width = 14, fig.height = 10, fig.align = 'center', fig.retina = 2)
```

This blog post explains a couple of workflows to connect to Big Query using `R`, and access Global Fishing Watch's public data. Since you found this post, I'm going to assume that you are somewhat familiar with Global Fishing Watch and are looking to explore and analyze the data using `R`. If you are not, check out our Science publication [Tracking the global footprint of fisheries](http://science.sciencemag.org/content/359/6378/904) as well as [Global Fishing Watch Open Data](http://globalfishingwatch.io/) portal. 

# What is BigQuery

[BigQuery](https://bigquery.cloud.google.com/welcome) is Google's platform to store and analyze massive datasets. It is very fast and well integrated to other Google products such as cloud storage, and it's free to use for up to 1TB of data analyzed each month, and up to 10GB of data stored. As any other database, it understands SQL and the online editor is a friendly place to learn and troubleshoot your queries.

To start using BigQuery, you need to have a gmail account and a BigQuery-enabled project. If you don't have this yet, please follow the steps in this quickstart guide  [quickstart guide ](https://cloud.google.com/bigquery/quickstart-web-ui) and come back when done. 

# Global Fishing Watch's data in BigQuery

Now that you have a BigQuery-enabled project, go the [BigQuery's UI page](https://bigquery.cloud.google.com). You should see your project in the side bar, above the Public Datasets project. Click on the small arrow next to your project name, then switch to project -> display project, and enter "global-fishing-watch" (without the quotes) on the Project ID. Click OK, and you should then have a `global-fishing-watch` project in your side bar. This project contains, two datasets: `"gfw_public_data"` and `"globa_footprint_of_fisheries"`. We will work on the latter, which contains the public data released with the *Science* publication. This dataset contains four tables 

  -  `fishing_effort`: Daily Fishing Effort and Vessel Presence at 100th Degree Resolution by Flag State and Gear Type, 2012-2016
  -  `fishing_effort_byvessel`:Daily Fishing Effort at 10th Degree Resolution by MMSI, 2012-2016
  -  `fishing_vessels`: Characteristics of each vessel included in the effort data
  -  `vessels`: This table includes all vessels that were matched to a registry, were identified through manual review or web searchers, or were classified by the neural network.

# Establishing a connection

The first step to use the data from R, is to set a connection with BigQuery. This is done using the `DBI` and `bigrquery` packages:

```{r, message = F}
library(tidyverse)
library(DBI)
library(bigrquery)

BQ_connection <-  dbConnect(bigquery(), 
                            project = 'global-fishing-watch',
                            dataset = "global_footprint_of_fisheries", 
                            billing = "ng-gfw") # your billing account name
```

We then need to authenticate the connection. This can be done when running your first query such as listing the tables in your connection through the function `dbListTable()`. This will trigger a prompt in your R session asking if you want to cache your credentials. Allow access and return to RStudio.

```{r message=F}
DBI::dbListTables(BQ_connection)
```

Now we are all set to start querying and analyzing Global Fishing Watch's data. There are a couple of approaches to do this, and I will illustrate each one with the following use cases

  1. Summarize the number of vessels by flag state in 2016
  2. Make a time series of fishing effort for China's trawlers fleet
  3. Make a map of fishing effort for a particular region of the ocean


# 1. Summarize the number of vessels by flag state and gear type

This is possibly one the first and simplest queries to do. For this use case, we will use the `dbplyr` and `bigrquery` packages that allow us to avoid the need to write SQL. We just write the `dplyr` verbs and functions we all love, and the `dbplyr` package translates them into SQL in the back-end. The main advantages of this approach is that it's very friendly and readable, and prevents us from the cognitive dissonance of switching between programming languages. However, SQL is a very large language and `dbplyr` does not do everything; it focuses on `SELECT` statements which are often what we use the most.   

The first step here is to connect to the table we want to query using the `tbl()` function:

```{r, message=F}
library(tidyverse) #loads dplyr and friends

fishing_vessels <- dplyr::tbl(BQ_connection, "fishing_vessels")
```

However, notice that the variable created in your environment is not a dataframe or tibble but instead a list. This is because `tbl()` creates a reference to the table in the remote database but does not bring the actual data into memory. When you print it out, you'll see it looks like a tibble but its class is  `tbl_sql`. 

```{r message = F}
fishing_vessels
class(fishing_vessels)
```

The most important difference between a local ordinary dataframe and a remote dataframe of class `tbl_sql` is that the your R code will run in the database. To do this efficiently, `dplyr` will be as lazy as possible by 1) not pulling data into R unless explicitly asked to, and 2) delaying the actual communication to the database until the last possible moment (i.e., after it collects all that you want to do).

Now, we can continue to use the dplyr verbs we are familiar with and summarize the table as we wish:

```{r}
summary_by_country_and_gear <- fishing_vessels %>% 
  filter(active_2016) %>% 
  group_by(flag, geartype) %>% 
  summarize(n_vessels = n_distinct(mmsi),
            total_GT = sum(tonnage)) %>% 
  arrange(desc(n_vessels))
```

As you will see, the object created in our environment is not the data we wanted. In fact the above code never touched the database, only recorded the instructions to query the data. To pull the data into a local  `tibble` we need to explicitly ask for it with the function `collect()`.

```{r, warning=FALSE, message = FALSE}
summary_by_country_and_gear <- collect(summary_by_country_and_gear)
```

We can the make a simple summarizing plot:

```{r}
top_20_flags <- summary_by_country_and_gear %>% 
  group_by(flag) %>% 
  summarize(n_vessels = sum(n_vessels)) %>% 
  top_n(20, n_vessels) %>% 
  pull(flag)

summary_by_country_and_gear %>% 
  filter(flag %in% top_20_flags) %>% 
  na.omit() %>% 
  ggplot(aes(x = forcats::fct_reorder(flag, n_vessels), y = n_vessels, fill = geartype))+
  geom_col()+
  coord_flip()+
  hrbrthemes::theme_ipsum()+
  ggsci::scale_fill_startrek()
```


Chinese Trawlers are, by far, the largest fleet in the Global Fishing Watch Database.

This approach is straight forward and works perfectly for simple queries. However, I recommend you become proficient with SQL to make the most of the power of BigQuery and Global Fishing Watch. This will help you troubleshoot when things don't work as expected and it will make it easier to reach out to the Global Fishing Watch community for help. A couple of great resources to learn are: [Learn SQL | Codecademy](https://www.codecademy.com/learn/learn-sql), and [Learn SQL the Hard Way](https://learncodethehardway.org/sql/). Another way to start learning SQL is to use the function `show_query()` from `dplyr`, which will show you what your R code gets translated as in SQL, behind scenes.

```{r, warning=FALSE}
fishing_vessels %>% 
  filter(active_2016) %>% 
  group_by(flag, geartype) %>% 
  summarize(n_vessels = n_distinct(mmsi),
            total_GT = sum(tonnage)) %>% 
  arrange(desc(n_vessels)) %>% 
  show_query()
```

# 2. Make a time series of fishing effort for China's trawlers fleet

For this analysis we need to summarize fishing by date, only for Chinese trawlers between 2013-2016. So, we need to join the effort and vessels characteristics data and filter effort for Chinese trawlers only. An inner joing is the perfect operation for this. 

Using the previous approach, we would write something like this:

```{r, error = T}
fishing_vessels <- dplyr::tbl(BQ_connection, "fishing_vessels")
fishing_effort_byvessel <- dplyr::tbl(BQ_connection, "fishing_effort_byvessel")

ts_china_effort <- fishing_effort_byvessel %>% 
  inner_join(fishing_vessels %>% 
               filter(flag == "CHN", geartype == "trawlers"), by = "mmsi") %>% 
  group_by(date) %>% 
  summarize(fishing_hours = sum(fishing_hours)) %>% 
  ungroup() %>% 
  arrange(date) %>% 
  collect()

head(ts_china_effort)
```

Until recently, joining datasets through `bigrquery` in this way was not possible. This has been implemented a couple weeks ago in the dev version of the `bigrquery` package, so make sure to install it for it to work. Still, some simple functions continue to be problematic and require some workarounds. For instance, the `date()` or `year()` functions -- both valid in SQL and R -- do not work as expected when querying data via `bigrquery` and dbplyr. 



Now lets plot this data to observe the effect of the chinese new year and the summer fishing moratoria on the temporal patterns of fishing effort. 

```{r}
moratoria_dates <- tibble(year = c(2013:2016)) %>% 
  mutate(start_date = lubridate::ymd(paste(year,"-06-01",sep = "")),
         end_date = lubridate::ymd(paste(year,"-08-01",sep = "")))

new_year_dates <- tibble(year = c(2013:2016),
                         start_date = c(lubridate::ymd("2013-02-07"),
                                        lubridate::ymd("2014-01-28"),
                                        lubridate::ymd("2015-02-16"),
                                        lubridate::ymd("2016-02-05")),
                         end_date = c(lubridate::ymd("2013-02-13"),
                                      lubridate::ymd("2014-02-3"),
                                      lubridate::ymd("2015-02-22"),
                                      lubridate::ymd("2016-02-11")))
```



```{r}
ggplot() +
  geom_rect(data = moratoria_dates, 
            aes(xmin = start_date, 
                xmax = end_date,
                ymin = 0,
                ymax = Inf,
                fill = "navyblue"),
            alpha = 0.5, 
            show.legend = TRUE) +
  geom_rect(data = new_year_dates, 
            aes(xmin = start_date, 
                xmax = end_date,
                ymin = 0,
                ymax = Inf,
                fill = "dodgerblue"),
            alpha = 0.5,
            show.legend = TRUE) +
  geom_line(data = ts_china_effort %>% 
               mutate(date = lubridate::ymd(date)) %>% 
               filter(lubridate::year(date) > 2012),
           aes(x = date, y = fishing_hours), 
           size = 0.3)+
  theme_minimal() +
  theme(axis.ticks = element_line(size = 0.5),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black"),
        axis.text.y = element_text(size = 10),
        axis.text.x = element_text(size = 10),
        axis.title = element_text(size = 10),
        legend.text = element_text(size = 6),
        legend.justification = "center",
        legend.position = "bottom",
        plot.margin = margin(2,2,2,2)) + 
  scale_x_date(date_breaks = "1 year", 
               date_labels = "%Y ") +
  xlab("") +
  scale_y_continuous(expand = c(0, 0),
                     labels = scales::comma) +
  ylab("Fishing hours")+
  scale_fill_manual(values = c("orange", "dodgerblue"),
                    name = " ",
                    labels = c("Chinese New Year", "Moratoria")) +
  guides(colour = guide_legend(override.aes = list(alpha = .5)))
```

Conclusion: Holidays can have as large an effect as strictly enforced policies on fishing activity. Thus, we need more holidays!

